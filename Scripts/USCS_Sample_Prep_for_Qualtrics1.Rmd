---
title: "USCS Prep Sample for Qualtrics 1"
output:
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 75
---

### Preparatory Steps

Consult `ReadMe.md` for instructions on how to configure the inputs
properly before running this script


Remember to update file paths and variables in `Config_and_Helper.R`

 **This code will output warnings and messages.** The warnings indicate
    a check is not met. These will be printouts with "Warning:" before
    them. If a check is passed, a message will be printed with "SUCCESS:"
    before it. If any warnings are printed, figure out why and report if
    the warning says to.

### Dependencies

```{r Load in Packages, message=FALSE, warning=FALSE}
if (!require("pacman")) install.packages("pacman")

# Loads in necessary packages, and installs them if you don't have them installed
pacman::p_load("tidyverse",
               "readxl",
               "stringi",
               "varhandle",
               "openxlsx")

# Load in configuration file variables and functions
source('Config_and_Helpers.R') 

options(scipen = 99999, # Remove scientific notation
        dplyr.summarise.inform = FALSE) # Remove summarize messages

knitr::opts_chunk$set(results = "asis", # Prints html tables nicely
                      echo=TRUE) # Show all code chunks in the output

Diagnostic_WB <- createWorkbook()
```

### Data Loading

- As of June 2023, we are ignoring the data that comes in from the Spend file as we do not include any of its variables in the final sample
- So disregard any anomalies with the spend dataframe
- The code may be removed for loading spend in the future

```{r Load in base and spend dataframes}
USCS_Base <- load_base() 
USCS_Spend <- load_spend()

f_str("There were {format(nrow(USCS_Base), big.mark = ',')} observations loaded in for BASE") %>% message()
f_str("There were {format(nrow(USCS_Spend),big.mark = ',')} observations loaded in for SPEND") %>% message()
```

```{r Missing Value Summary}
# Variables to summarize number of missing values
miss_vars <- c("first_nm", 
               'last_nm',
               "raw_fico",
               "fico_range",
               "raw_age",
               "share_of_wallet_amex",
               "size_of_wallet",
               "customer_spend",
               "account_spend")

# Table with number and percent of missing values for key variables
# This is mostly just for logging what's happened
# just make sure no variables have a large number of missing values, in my (Beck's) 5 months, I haven't seen anything with more than 0.05% missing
miss_vals <- USCS_Base %>%
  select(all_of(miss_vars)) %>%
  summarise_all(~sum(is.na(.))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "n_missing") %>%
  mutate("Percent Missing" = paste0(round(n_missing / nrow(USCS_Base) * 100, 4), " %")) %>% 
  arrange(desc(n_missing)) %>% make_nice_table("Number of Missing Values per Key Variable")
```


```{r Filtering base and spend}
# Change these monthly based on OPS instructions
# Comment out filters that do not need to be applied

USCS_Base <- USCS_Base %>% 
  # *Change new_smart_rev to numeric
  #mutate(new_smart_rev = as.numeric(new_smart_rev_char)) %>%
  
  #*From Ops email: (please take out all counts for Augment 54);
  # filter(!cell_code %in% c("","CNGR54")) %>% 
  #*from ops email 9 28 22: #take out the three people missing marketer_code
  filter(marketer_code != "") 

USCS_Spend <- USCS_Spend %>%
  # Remove records with blank space at start of ID
  filter(substring(gmpi_base_cust_id, 1, 1) != " ") 
```


### Cell Code Checking

-   Compare the total amount of main sample received to the amount of
    sample requested
-   Verify no missing cell codes

```{r Check Cell Codes, message=FALSE}
# Create a frequency table of each cell code
cell_code_freq <- USCS_Base %>% 
  freq_table("cell_code", caption = "Cell Code Frequencies")
```

```{r }
# Break the cell codes into the main survey codes and augmented survey codes
# Main Survey has 'Cell_Codes' that start with 'CCSG' 
main_survey_ccs <- cell_code_freq %>% filter(str_starts(cell_code, "CCSG")) 
aug_survey_ccs <- cell_code_freq %>% 
  filter(!str_starts(cell_code, "CCSG"))
```

```{r message=FALSE}
# Load in the expected frequencies from the helper file
req_sp_codes <- read_excel(SAMPLE_PREP_PATH,
                           sheet = "Sp_Code_Freqs") %>% 
  set_names(c("sp_code", "card_name", "Total")) %>% 
  drop_na(sp_code) %>% # Remove blank spaces if they were kept in
  mutate(sp_code = glue("SP{sp_code}")) %>% 
  # If blank spaces were loaded in, the columns might be characters when we want them to be numbers, this will fix that
  type_convert()
  
```

```{r}
if (sum(main_survey_ccs$Freq) != sum(req_sp_codes$Total)){
  warning("The Main sample recieved does not match the sample requested
          Provide an explanation or resolution to the difference. Figure out what's wrong.")
} else{
  message("SUCCESS: The size of the main Sample recieved matches the sample requested")
}

missing_ccs <- cell_code_freq %>% dplyr::select(cell_code) %>% 
  filter(!cell_code %in% unique(c(main_survey_ccs$cell_code,
                                  aug_survey_ccs$cell_code)))

if (nrow(missing_ccs) > 0) {
  warning("Cell Code detected not in main or augmented survey detected. Check MISSING_CCS dataframe for these codes")
} else{
  message("SUCCESS: All cell codes match format for main or augmented surveys")
}
```

### Check to make sure everyone has a spend and tenure and new-product-tenure.

```{r}
# Check missing account spend and tenure
miss_spend_and_ten <- USCS_Base %>% dplyr::select(account_spend, t_add) %>% 
  sapply(function(x) sum(is.na(x))) %>% as.data.frame() %>% 
  set_names("No. Missing Values")

miss_spend_and_ten_tab <- miss_spend_and_ten %>% 
  make_nice_table("Missing Values Account Spend and Tenure Add") 

if(miss_spend_and_ten["account_spend",] > 0){
  warning("ACCOUNT SPEND has missing values")
} else{
  message("SUCCESS: ACCOUNT SPEND does not have missing values")
}

if(miss_spend_and_ten["t_add",] > 0){
  warning("New Product Tenure has missing values")
}else{
  message("SUCCESS: New Product Tenure does not have missing values")
}
# Check missing set up dates
miss_setup_dt <- USCS_Base[USCS_Base$setup_dt == "",]
if (nrow(miss_setup_dt) > 0){
  warning("Missing Set up Date. Check miss_setup_dt variable")
}else{
  message("SUCCESS: No missing set up dates")
}

# Check missing marketer codes
miss_marketer_code <- USCS_Base[USCS_Base$marketer_code == "",]
if (nrow(miss_marketer_code) > 0){
  warning("Missing Marketer Code. Check miss_marketer_code variable")
}else{
  message("SUCCESS: No missing marketer codes")
}
```


-   The next two chunks output two excel sheets to be sent to the operations
    manager in an email. A third sheet is added later with removed tenure and spend as well.
    
- I tend to send everything over at once at the end because then you don't have to wait for responses and the code runs relatively fast

    -   Excel sheet `Main_Code_Freqs` is found in the
        `Files_to_send/USCS_Diagnostics_MONTH_YEAR.xlsx` file

    -   Excel Sheet `Cell_Code_Freqs` is found in the
        `Files_to_send/USCS_Diagnostics_MONTH_YEAR.xlsx` file

```{r }
# Table with marketer code frequencies for cell codes "CCSG01", "CCSG02", "CCSG03"
main_code_freq <- USCS_Base %>% 
  filter(cell_code %in% c("CCSG01", "CCSG02", "CCSG03")) %>% 
  freq_table("marketer_code", 
             caption = "Marketer Code Frequencies for Main Cell Codes")

# Write to excel to send to OPS Manager
addWorksheet(Diagnostic_WB, "Main_Code_Freqs")
writeData(Diagnostic_WB, "Main_Code_Freqs", main_code_freq)
```

```{r}
cell_code_freq <- cell_code_freq %>% 
  # Extract two digit number from cell code and append it to either Drop or Augment
  mutate(naw_cell_code = if_else(str_starts(cell_code, "CCS"),
                                 paste("CCSG DROP", 
                                        str_extract(cell_code, "[0-9]{2}")),
                                 paste("Augment Cell",
                                       str_extract(cell_code, "[0-9]{2}")))
         ) %>% 
  dplyr::select(cell_code, naw_cell_code, Freq) %>% 
  arrange(str_extract(cell_code, "[0-9]{2}"))

# Save to output excel file to be sent to PM
addWorksheet(Diagnostic_WB, "Cell_Code_Freqs")
writeData(Diagnostic_WB, "Cell_Code_Freqs", cell_code_freq)

ccf <- cell_code_freq %>% 
  make_nice_table("Cell Code Frequencies with NAW Cell Codes")

saveWorkbook(Diagnostic_WB, file = f_str("../Files_to_send/USCS_Diagnostics_{MONTH}_{YEAR}.xlsx"), overwrite = TRUE)
```

### Check for duplicates

```{r}
USCS_Base_dupes <- USCS_Base[duplicated(USCS_Base$gmpi_base_cust_id),]
USCS_Spend_dupes <- USCS_Spend[duplicated(USCS_Spend$gmpi_base_cust_id),]

if (nrow(USCS_Base_dupes) > 0){
  warning("Duplicate Base customer IDs in the Allbase dataframe")
  print(USCS_Base_dupes$gmpi_base_cust_id)
} else{
  message("SUCCESS: No duplicates in Allbase dataframe")}

if (nrow(USCS_Spend_dupes) > 0){
  warning("Duplicate base customer IDs in the Allspend dataframe")
  print(USCS_Spend_dupes$gmpi_base_cust_id)
} else{
  message("SUCCESS: No duplicates in Allspend dataframe")}
```

### Merge Allspend and Allbase

-   Code to account for the all Augments when assigning values to
    'naw_cell_code'
-   Add code for new Augments
-   Make sure the proper number of records remain
- Once again, this may be altered if we are removing the spend dataframe.

```{r}
 # Left join ensures only USCS_Base matters, If spend matters again, change to inner_join
USCS_Sample <- left_join(USCS_Base, USCS_Spend, by = "gmpi_base_cust_id") %>%
  mutate(raw_setup_dt = setup_dt,
          setup_dt = if_else(setup_dt == "0001-01-01",
                       NA_character_, setup_dt),
          setup = as_date(setup_dt, format = "%Y-%m-%d"),
          bf_setup_year = year(setup),
          bf_setup_month = month(setup),
          bf_setup_day = day(setup),
         
         tenure_var = 12*(YEAR-1-bf_setup_year)+(MONTH_NO+12-bf_setup_month),

         tenure_cat = case_when(
           tenure_var <   5 ~ 1,
           tenure_var <  16 ~ 2,
           tenure_var <  25 ~ 3,
           tenure_var <  49 ~ 4,
           tenure_var <  73 ~ 5,
           tenure_var < 109 ~ 6,
           tenure_var < 145 ~ 7,
           tenure_var < 181 ~ 8,
           tenure_var < 241 ~ 9,
           TRUE ~ 10),
         
         spend = case_when(
           account_spend <=    0 ~ "A",
           account_spend <  1500 ~ "B",
           account_spend <  2500 ~ "C",
           account_spend <  5000 ~ "D",
           account_spend <  7500 ~ "E",
           account_spend < 10000 ~ "F",
           account_spend < 20000 ~ "G",
           account_spend < 35000 ~ "H",
           account_spend < 50000 ~ "I",
           TRUE ~ "J"),
         
         naw_cell_code = if_else(str_starts(cell_code, "CCSG"),
                                 gsub("CCSG", "DROP", cell_code),
                                 gsub("[A-Z]{2,}", "CELL", cell_code)),
         
         naw_type = if_else(cell_code %in% c("CCSG01", "CCSG02", "CCSG03"),
                            "MAIN",
                            "AUGMENT")
         )


if (nrow(USCS_Sample) != nrow(USCS_Base)){
  warning("Size of merged dataframe does not match original dataframe.")
} else{
  message("SUCCESS: Size of merged dataframe matches original dataframe")
}

```

### Checking for Duplicate Keys in Merged Data frame

```{r message=FALSE}
# Checking distribution of sample by Augment/MAIN;
naw_freq_table <- USCS_Sample %>%
  freq_table(c("naw_type", "naw_cell_code"),
             caption="Naw Type vs Naw Cell Code Frequencies")
```

```{r }
# Identify duplicates for customer id and username/password
cust_id_dupes <- USCS_Sample[duplicated(USCS_Sample$gmpi_base_cust_id),]
pers_dupes <- USCS_Sample[duplicated(USCS_Sample[,c("personalization1", "personalization2")]),]

if (nrow(cust_id_dupes) > 0){
  warning("There are customer ID duplicates in the merged dataframe")
  print(cust_id_dupes$gmpi_base_cust_id)
} else{
  message("SUCCESS: No Customer ID duplicates in the merged dataframe")
}

if (nrow(pers_dupes) > 0){
  warning("There are userID/password duplicates in the merged dataframe")
  print(pers_dupes[,c("personalization1", "personalization2")])
} else{
  message("SUCCESS: No userID/password duplicates in the merged dataframe")
}
```

### DMA Frequency

-   Make sure all DMA Codes are valid using the `DMA_Checks` sheet of the
    sample prep excel file.

```{r message=FALSE}
# Load in valid dmas
valid_dmas <- read_excel(SAMPLE_PREP_PATH,
                         sheet = "Valid_DMA_Codes") %>% 
  pull(Valid_DMA)
```

```{r }
# identify invalid dma's if any and get frequencies
invalid_dmas <- USCS_Sample %>% filter(!best_dma_cd %in% valid_dmas) %>% group_by(best_dma_cd) %>% summarize(n = n()) 

if (nrow(invalid_dmas) > 0){
  warning("There are invlaid DMA Codes in the file. Here are the codes and number of occurrences:")
  invalid_dmas %>% make_nice_table("Invalid DMA Code Frequencies") 
} else{
  message("SUCCESS: No invalid DMAs found in file")
}
```

### Saving and Loading dataframe before removals

- Because we automatically remove bad spends, tenures, and year of birth before confirming with PM, we save the dataset before removals, so we can easily return to it if we need to modify the code to keep these people in the dataframe

```{r}
save(USCS_Sample, file="../Data/USCS_Sample_Preremovals.Rdata")
```

```{r}
# Uncomment this to load in the image of the USCS_Sample dataframe before removals
# load("../Data/USCS_Sample_Preremovals.Rdata")
```

### Invalid Setup Date Check

```{r}
to_remove_setup_dt <- USCS_Sample %>% 
  filter(is.na(setup_dt)) %>% 
  select(gmpi_base_cust_id, marketer_code, naw_cell_code, raw_age, raw_setup_dt, card_anniv_dt)

if (nrow(to_remove_setup_dt) > 0){
  warning(f_str('There were {nrow(to_remove_setup_dt)} people who had a missing setup date or setup date of 01-01-0001'))
  warning("Verify with the PM if they are okay with these being removed in the email at the end of this script")
  
  # Save the removals to the output workbook
  addWorksheet(Diagnostic_WB, "Removed_Setup_DT")
  writeData(Diagnostic_WB, "Removed_Setup_DT", to_remove_setup_dt) 
} else {
  message("SUCCESS: No Observations with invalid Setup Dates")
}

```

### Age Check

-   Make sure no one is less than 18 or older than 120

    -   Note errors
    -   Any deletions will be put into the `Files_to_send/USCS_Diagnostics_MONTH_YEAR.xlsx` file
      - Sheet named "Removed_YOB"
      - Note this sheet will be empty if there are no observations removed

```{r}
to_remove_yob <- USCS_Sample %>% filter(!is.na(raw_age) & (raw_age > 120 & raw_age < 2000)) %>% 
  select(gmpi_base_cust_id, marketer_code, naw_cell_code, raw_age, setup_dt, card_anniv_dt)

if (nrow(to_remove_yob) > 0){
  warning(f_str('There were {nrow(to_remove_yob)} people who are too old (>120) or having missing age '))
  warning("Verify with the PM if they are okay with these being removed in the email at the end of this script")
  
  # Save the removals to the output workbook
  addWorksheet(Diagnostic_WB, "Removed_YOB")
  writeData(Diagnostic_WB, "Removed_YOB", to_remove_yob) 
}
```


### Frequency Tables for Spend and Tenure

-   Split the sample into Main and Augment

-   Frequency tables of spend tenure categories, and tenure_var for main
    samples

```{r}
# Split dataframe into main and augmented
USCS_Main <- USCS_Sample %>% filter(naw_type == "MAIN") %>% 
  mutate(customer_id = gmpi_base_cust_id %>% as.numeric())
USCS_Augment <- USCS_Sample %>% filter(naw_type == "AUGMENT")

```

```{r}
spend_freq_table <- USCS_Main %>% 
  freq_table("spend", caption="Spend Category Frequencies")

tenure_freq_table <- USCS_Main %>% 
  freq_table("tenure_cat", caption="Tenure Category Frequencies")

spend_freq_table_cat1 <- USCS_Main %>% 
  filter(tenure_cat == 1) %>%
  freq_table("spend", caption="Spend Category Freqs for Tenure Category 1")

tenure_freq_table_cat1 <- USCS_Main %>% 
  filter(tenure_cat == 1) %>% 
  freq_table("tenure_var", caption="Tenure Var Frequencies for Tenure Category 1")
```

### Sp Code Checking

-   Compare totals for desired sp codes to requested sp code totals

```{r}
main_sp_codes <- USCS_Main %>% 
  freq_table("marketer_code", caption = "Sp Code Frequencies")
```

```{r}
# Check if the requested totals for each code matches the observed total
check_sp_codes <- main_sp_codes %>% 
  dplyr::select(marketer_code, Freq) %>% 
  left_join(req_sp_codes, by = c("marketer_code" = "sp_code")) %>% 
  mutate(difference = abs(Freq - Total)) %>% # This difference should be 0
  rename(Obs_Freq = Freq, Req_Freq = Total)


if (sum(check_sp_codes$difference) > 0){
  warning("Frequencies of Observed Sp Codes do not match requested totals for the following codes")
  print(check_sp_codes %>% filter(difference > 0))
} else{
  message("SUCCESS: All observed frequencies of sp codes match requested totals. ")
}
```

-   Ensure Requested Sp Codes do not have spending category A.
  - Is there anyone with spend <= 0 that shouldn’t be?
  - Are there products that can have spend <= 0 that have no observations with spend <= 0?


```{r}
# The sp codes below should not have SPEND <= 0;
sp_code_no_a <- c("SP111",
                  "SP112",
                  "SP113",
                  "SP114",
                  "SP115",
                  "SP117",
                  "SP118",
                  "SP123",
                  "SP127",
                  "SP132",
                  "SP136",
                  "SP145",
                  "SP153",
                  "SP156") # SP 156 added in JULY 2018

# Sp codes that are allowed to have no or negative spend
sp_code_a <- USCS_Main$marketer_code[!USCS_Main$marketer_code %in% sp_code_no_a] %>% unique()

# Sp codes observed to have spend <= 0
obs_sp_code_a <- USCS_Main[USCS_Main$spend == "A",]$marketer_code %>% unique()

# Identify if sp codes that should not have no spend have no spend
wrong_no_spends <- sp_code_no_a[sp_code_no_a %in% obs_sp_code_a]

# Identify if sp_codes that can have no spend have observation with no spend
missing_no_spends <- sp_code_a[!sp_code_a %in% obs_sp_code_a]

if (length(wrong_no_spends) > 0) {
  for (code in wrong_no_spends) {
    warning("Sp Code: {code} has spend <= 0 when it should not" %>% f_str())
    cat("\n")}
  warning("Alert Operations for confirmation to exclude them") # This is not in the code and would need to be added
} else{
  message("SUCCESS: All SP Codes who should not have spend <= 0, do not have spend <= 0")
} 


if (length(missing_no_spends) > 0) {
  for (code in missing_no_spends) {
    warning("Sp Code: {code} has no observations spend <= 0 when it is allowed too" %>% f_str())
    cat("\n")}
  warning("Check the UC file to see what proportion of the pre and post suppression counts are for $0 spend on that product.  Given the sample request, how likely is it that we received no $0 spenders? If it seems unreasonable, you should discuss the matter with operations. If it's reasonable, just note in the next chunk and move on.")
} else{
  message("SUCCESS: All SP Codes who can have spend <= 0, have observations with spend <= 0")
} 
```

-- This is an example note from June 2023 of when this occurred for SP code 154

```{r}
# sp154 <- USCS_Main %>% filter(marketer_code == 'SP154')
# 
# message(f_str('There were {nrow(sp154)} samples pulled for Marketer Code 154. The UC file for Q2 2023 shows that the post suppression count percentage is 0.1% for 0 spend. Given the small sample pulled for SP154 and the 0.1% likelihood that the sample is 0 spend, having no 0 spend in our sample is okay.'))
# 
# sp154 %>% 
#   select(account_spend) %>%
#   summary()
```


### New Open Segment

-   New Open Segment file received every May/June

-   The code reads in a list customer_ids classified segments.

-   No one in the Main sample should be in this file. The dataset that is
    created in the merge in the last step should have no records.

    -   If someone appears here, note and resolve/explain the issue

```{r message=FALSE}
# Load in new segment data
open_seg <- read_csv(OPEN_SEG_PATH) %>% 
  rename(gmpi_base_cust_id = cust_xref_id) %>% 
  mutate(customer_id = gmpi_base_cust_id %>% as.numeric()) # Get numeric ID
```

```{r}
# check distributions

# Customer ID Distribution in Main
cid_main <- USCS_Main %>% 
  dplyr::select(customer_id_main = customer_id) %>% 
  summary() %>% make_nice_table("Customer ID Main Descriptive Stats")

# Open Segment Customer ID Distribution
cid_open <- open_seg %>%  
  dplyr::select(customer_id_open_seg = customer_id) %>% 
  summary() %>% make_nice_table("Customer ID Open Segment Descriptive Stats")

open_seg_freq <- open_seg %>% 
  freq_table("OPEN_MANAGED_SEGMENT", caption="Open Managed Segment Freqs")

open_seg_dupes <- open_seg[duplicated(open_seg$customer_id),]

if (nrow(open_seg_dupes) > 0){
  warning("Duplicated Customer IDs in New Open Segment File")
} else{
  message("SUCCESS: NO Duplicated Customer IDs in New Open Segment File")
}
```

```{r}
# Check if someone in the main file is in the open segment file
open_seg_check <- USCS_Main %>% 
  inner_join(open_seg, by = c("gmpi_base_cust_id", "customer_id"))

if (nrow(open_seg_check) > 0){
  warning(f_str("{nrow(open_seg_check)} Customers in the main file appear in the new segment file"))
  cat('\n')
  if (nrow(open_seg_check) > 3000){
    warning("More than 3000 main file customers appear in the new segment. REPORT")
  } else{
   message("Less than 3000 main file customers appear in the new segment. Note and explain these customers. No need to report")
  }
} else{
  message("SUCCESS: No main file customers appear in the new segment")
}
```

```{r }
# Generate count for early and non-early tenure
et_tab <- USCS_Main %>% 
  count(marketer_code, tenure_cat) %>%
  spread(tenure_cat, n, fill = 0)

et_tab <- et_tab %>% 
  # Create new variables for the split of early and non-early tenure counts
  mutate(et = `1`,
         non_et = rowSums(et_tab[3:11])) %>% 
  dplyr::select(marketer_code, et, non_et) %>% 
  janitor::adorn_totals('row') %>% 
  make_nice_table("Early vs Non-Early Tenure by SP Code")
```

### Diagnostic Tests

-   Keeping the 'Selected' functionality in for now.
-   I wrote an AB split testing function in case that is desired in the future instead

```{r}
mrktr_naw <- table(USCS_Main$marketer_code, USCS_Main$naw_cell_code) %>%
  make_nice_table("Marketer Code vs NAw Cell Code")


# perform ab split (if desired)
# makes new variables based on split
# The create_ab_split function will create the "selected" variable. So if you are performing the ab_split, remove the line that defaults the selected variable to 0.
USCS_Main <- USCS_Main %>% 
  #create_ab_split(strat_var = 'marketer_code', sample_size = 0.5) %>% # Stratify sample 50% of obs for each marketer code
  mutate(selected = 0) %>% # comment this out if using the ab_split
  mutate(sp_code = str_extract(marketer_code, "[0-9]{3}") %>% # Extract marketer code (i.e. 101 from SP101)
          as.numeric(),
         # Extract drop code (i.e. 1 from DROP 01)
         drop_code = str_extract(naw_cell_code, "[0-9]{2}") %>% 
          as.numeric(),
         mv_nps_ind = if_else(selected == 0, "NPS", "MV"),
         mr_in_n = if_else(mr_in == 'Y', 1, 2),
         subject_line = if_else(selected == 0, 6, 7))
```

```{r}
mr_in_ct <- table(USCS_Main$mr_in,USCS_Main$mr_in_n)

if (mr_in_ct[1,1] == 0 & mr_in_ct[2,2] == 0){
  message("SUCCESS: MR IN split worked correctly")
} else{
  warning("MR IN split did not work correctly.")}
```

# Augment Checking

```{r}
USCS_Augment <- USCS_Augment %>% filter(!marketer_code %in% c("", "SP138", "SP139")) %>% 
  mutate(customer_id = gmpi_base_cust_id %>% as.numeric())

cell_code_naw_sp_ct <- USCS_Augment %>% 
  freq_table(c("naw_cell_code", "cell_code", "marketer_code"), 
             caption="Naw Cell Code vs Cell Code vs Sp Code Frequencies")
```

```{r}
# Check if someone in the augmented file is in the open segment file
open_seg_check_aug <- USCS_Augment %>% 
  inner_join(open_seg, by = c("gmpi_base_cust_id", "customer_id"))

if (nrow(open_seg_check_aug) > 0){
  warning(f_str("{nrow(open_seg_check_aug)} Customers in the augmented file appear in the new segment file"))
  cat('\n')
  if (nrow(open_seg_check_aug) > 3000){
    warning("More than 3000 augmented file customers appear in the new segment. REPORT")
  } else{
   message("Less than 3000 augmented file customers appear in the new segment. Note and explain these customers. No need to report")
  }
} else{
  message("SUCCESS: No augmented file customers appear in the new segment")
}
```

```{r}
# Add the open segment info to the augment file
USCS_Augment <- USCS_Augment %>% 
  left_join(open_seg, by = c("gmpi_base_cust_id", "customer_id"))
```

### Removing Bad Spend and Tenure in the Augment File

-   Checking expected specs to actual specs for augmented data.

-   Expected specs found in `Sample_Prep_Helper.xlsx` sheet *Augment_Specs*

-   Check tenure category and var Frequency to make sure they align with
    the expected specs

    -   Note errors
    -   Any deletions will be put into the `Files_to_send/USCS_Diagnostics_MONTH_YEAR.xlsx` file
      - Sheet named "Removed_Tenure_or_Spend"
      - Note this sheet will be empty if there are no observations removed

```{r message=FALSE}
exp_cell_codes <- read_excel(SAMPLE_PREP_PATH,
                             sheet = "Augment_Specs")
```

```{r}
to_remove_tenure_spend <- USCS_Augment %>% 
  dplyr::select(gmpi_base_cust_id, naw_cell_code, tenure_var, 
                      account_spend, marketer_code, setup_dt) %>%  
  inner_join(exp_cell_codes, by="naw_cell_code")  %>% 
  mutate(tenure_var_max = if_else(is.na(tenure_var_max), Inf, tenure_var_max),
         flag_tenure = tenure_var < tenure_var_min | tenure_var > tenure_var_max,
         flag_spend = (account_spend <= 0 & min_spend == ">$0")) %>% 
  filter(flag_spend | flag_tenure)


if (nrow(to_remove_tenure_spend) > 0){
  warning(f_str("There are {nrow(to_remove_tenure_spend)} people flagged for deletion in the augment file due to bad account spends or tenures. These will be found in the `Files_to_send/USCS_Diagnostics_MONTH_YEAR.xlsx` file. Verify with the PM if they are okay with these being removed in the email at the end of this script"))

} else{
  message("SUCCESS: NO people deleted due to bad account spends or tenure in the augment file")
}
 
addWorksheet(Diagnostic_WB, "Removed_Tenure_or_Spend")
writeData(Diagnostic_WB, "Removed_Tenure_or_Spend", to_remove_tenure_spend) 
saveWorkbook(Diagnostic_WB, file = f_str("../Files_to_send/USCS_Diagnostics_{MONTH}_{YEAR}.xlsx"), overwrite = TRUE)
```

```{r SUBJECT LINE}
# perform ab split (if desired)
# makes new variables based on split
# The create_ab_split function will create the "selected" variable. So if you are performing the ab_split, remove the line that defaults the selected variable to 0.
USCS_Augment <- USCS_Augment %>% 
  #create_ab_split(strat_var = 'marketer_code', sample_size = 0.5) %>% # Stratify sample 50% of obs for each marketer code
  mutate(selected = 0) %>% # comment this out if using the ab_split
  mutate(sp_code = parse_number(marketer_code),
         mv_nps_ind = if_else(selected == 0, "NPS", "MV"),
         mr_in_n = if_else(mr_in == 'Y', 1, 2),
         subject_line = if_else(selected == 0, 6, 7)) # Change if PM instructs to

ncc_mv_nps <- USCS_Augment %>% freq_table(c("naw_cell_code", "mv_nps_ind"),
                          "naw cell code vs MV NPS IND Freqs")
```

```{r}
sel_sbj_line <- USCS_Augment %>%
  freq_table(c("selected", "subject_line"), "Selected vs Subject Line Freqs")
```

**ACTION NEEDED. STOP HERE**

- Now that you completed the first step of the sample prep, write an email to the PM.
- They need to confirm if you can remove the bad tenure, spend, and YOB people we removed and they verify the counts we recieved
- First copy the diagnostic file into the Communications subfolder of the project folder that the PM has access to (e.g, `\\pm1\27-610\Sampling-Weighting\2023_07\Communications\`)
  - Create this folder if it is not already there
- Then write an email including a link to that file and briefly saying what was removed and why it was removed
- This is an example email. I had already run step 2 before sending this email, but you can just modify the first line if you want to send it now.
  - It's probably best to send now in case they do not want certain people removed.


Hi Ryan,

The USCS Sample has been prepped. It can be found here: `\\pm1\27-610\Sampling-Weighting\2023_07\AllSample\AmexGABMUSCSSurvey_202307_2023-06-28.csv`

The following excel contains diagnostic information about cell frequencies and individual samples that were removed: `\\pm1\27-610\Sampling-Weighting\2023_07\Communications\USCS_Diagnostics_JUL_2023.xlsx`
•	There were 98 people removed because of too high tenure in Cell35. All of them were set up in February, which is greater than the desired maximum of 120 days. These can be found in the above excel. 
•	There were 4 people removed for having birth years within the past 18 years. Their setup dates are much older than 18 though, so the at least one of those variables are wrong. They are currently removed from the final sample but can be put back in if desired. These can be found in the above excel. 

Let us know if you are okay with these being deleted or if you want them put back.

Best,
Beck


**IF THEY SAY YOU CAN REMOVE ALL THOSE PEOPLE**
  - Run the next chunk

**IF THEY SAY YOU SHOULD NOT REMOVE CERTAIN PEOPLE**
  - Comment out certain lines in the next chunk to not remove them


```{r}
# Remove bad SetupDate
removal_count_setup_dt_main <- USCS_Main %>% 
  semi_join(to_remove_setup_dt, by = 'gmpi_base_cust_id') %>% 
  nrow()

removal_count_setup_dt_augment <- USCS_Augment %>% 
  semi_join(to_remove_setup_dt, by = 'gmpi_base_cust_id') %>% 
  nrow()

USCS_Main <- USCS_Main %>% anti_join(to_remove_setup_dt, by = 'gmpi_base_cust_id') # Line to comment out if PM does not want these samples removed
USCS_Augment <- USCS_Augment %>% anti_join(to_remove_setup_dt, by = 'gmpi_base_cust_id') # Line to comment out if PM does not want these samples removed

# Remove bad YOB
removal_count_yob_main <- USCS_Main %>% 
  semi_join(to_remove_yob, by = 'gmpi_base_cust_id') %>% 
  nrow()

removal_count_yob_augment <- USCS_Augment %>% 
  semi_join(to_remove_yob, by = 'gmpi_base_cust_id') %>% 
  nrow()

USCS_Main <- USCS_Main %>% anti_join(to_remove_yob, by = 'gmpi_base_cust_id') # Line to comment out if PM does not want these samples removed
USCS_Augment <- USCS_Augment %>% anti_join(to_remove_yob, by = 'gmpi_base_cust_id') # Line to comment out if PM does not want these samples removed

# Removing Bad tenure and Spend
removal_count_tenure_spend <- USCS_Augment %>% 
  semi_join(to_remove_tenure_spend, by = "gmpi_base_cust_id") %>% 
  nrow()

USCS_Augment <- USCS_Augment %>% anti_join(to_remove_tenure_spend, by = "gmpi_base_cust_id") # Comment this out if not removing

# Print removal counts
cat("Number of removals due to bad SetupDate in USCS_Main:", removal_count_setup_dt_main, "\n")
cat("Number of removals due to bad SetupDate in USCS_Augment:", removal_count_setup_dt_augment, "\n")
cat("Number of removals due to bad YOB in USCS_Main:", removal_count_yob_main, "\n")
cat("Number of removals due to bad YOB in USCS_Augment:", removal_count_yob_augment, "\n")
cat("Number of removals due to bad tenure and spend in USCS_Augment:", removal_count_tenure_spend, "\n")

```

```{r}
# Store important sample datasets for the second script.
save(USCS_Augment, USCS_Main, file=f_str("../Data/unweighted_samples_{MONTH}_{YEAR}.Rdata"))
```

```{r message=FALSE}
# IF YOU ARE RUNNING `USCS_Weighting.Rmd` right after this, run this chunk and then you DO NOT have to reload in the data with the step `load(f_str("../Data/unweighted_samples_{MONTH}_{YEAR}.Rdata"))`
# There's no harm if you do, but the dataframes you need will stay in your environment

rm.all.but(keep = c('USCS_Main', 'USCS_Augment'))
```
